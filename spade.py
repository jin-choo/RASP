import neo, numpy as np, quantities as pq, yaml, time, signal, os, csv, datetime
from elephant.spade import spade
from itertools import combinations, permutations, groupby
from sklearn import metrics
from CN2Simulator.motif_gen import *


class TimeOutException(Exception):
    pass


def alarm_handler(signum, frame):
    raise TimeOutException()


def itemset_to_number(max_neuron, k_tuple, itemset):
    number = itemset[0] * pow(max_neuron, k_tuple - 1)
    for k in range(1, k_tuple):
        number += itemset[k] * pow(max_neuron, k_tuple - 1 - k)
    return number


def number_to_itemset(number, max_neuron, k_tuple):
    q, mod = divmod(number, pow(max_neuron, k_tuple - 1))
    itemset = [q]
    for k in range(1, k_tuple + 1):
        q, mod = divmod(mod, pow(max_neuron, k_tuple - 1 - k))
        itemset.append(q)
    return itemset


def neurons_to_number(neurons, max_neuron, k_tuple):
    number = neurons[0] * pow(max_neuron, k_tuple)
    for k_neurons in range(1, k_tuple + 1):
        number += neurons[k_neurons] * pow(max_neuron, k_tuple - k_neurons)
    return number


def neurons_number_to_neurons(number, max_neuron, k_tuple):
    q, mod = divmod(number, pow(max_neuron, k_tuple))
    neurons = [q]
    for k_neurons in range(1, k_tuple + 1):
        q, mod = divmod(mod, pow(max_neuron, k_tuple - k_neurons))
        neurons.append(q)
    return tuple(sorted(neurons))


def neurons_number_to_unsorted_neurons(number, max_neuron, k_tuple):
    q, mod = divmod(number, pow(max_neuron, k_tuple))
    neurons = [q]
    for k_neurons in range(1, k_tuple + 1):
        q, mod = divmod(mod, pow(max_neuron, k_tuple - k_neurons))
        neurons.append(q)
    return neurons


def spade_ndcg_rc(motif_type, NIDs, recording_time, background_firing_rate, motif_firing_rate, probabilistic_participation, temporal_jitter, time_warping, motif_neurons_numbers, motif_max_lags, motif_max_spikes, bin_size, dithering, start_time, seed, top_K_list):
    # Synthetic data generated by SimulMotif
    # Load simulation parameters
    with open("params.yaml") as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params["NIDs"] = NIDs
    params["recording"]["recording_time"] = recording_time
    params["background"]["firing_rate"] = [background_firing_rate, background_firing_rate]

    if probabilistic_participation > 1:
        params["noise"]["probabilistic_participation"] = 1 - 1 / probabilistic_participation

    k_tuples = motif_neurons_numbers[0]

    params["noise"]["temporal_jitter"] = temporal_jitter
    params["noise"]["time_warping"] = time_warping

    params[f"motif_type_{motif_type}"]["firing_rate"] = motif_firing_rate
    params[f"motif_type_{motif_type}"]["neurons"] = motif_neurons_numbers[0]
    params[f"motif_type_{motif_type}"]["motifs"] = motif_neurons_numbers[1]
    if motif_type > 1:
        params[f"motif_type_{motif_type}"]["max_lags"] = motif_max_lags
        winlen = math.ceil((motif_neurons_numbers[0] - 1) * motif_max_lags / bin_size)
        if motif_type == 3:
            params[f"motif_type_{motif_type}"]["max_spikes"] = motif_max_spikes
    else:
        winlen = round(math.ceil(100.0 / bin_size))

    # Genereate non-motif activity
    # spike_time: list containing every spikes
    # spike_time_motif: list containing spikes induced by motifs
    spike_time, spike_time_motif = non_motif_gen(params, seed=6*seed)

    # Generate motif activity
    gts = motif_gen(spike_time, spike_time_motif, motif_type, params, seed=6*seed+motif_type)

    sum_count = 0
    spiketrains = []
    for x in spike_time:
        spiketrains_append = neo.core.SpikeTrain(np.clip(np.array(x) * 1000, 0, recording_time * 1000) * pq.ms, units='ms', t_stop=recording_time * 1000 * pq.ms)
        spiketrains.append(spiketrains_append)
        sum_count += spiketrains_append.size

    stopped = False

    try:
        start = time.time()  # 시작 시간 저장
        signal.signal(signal.SIGALRM, alarm_handler)
        signal.alarm(100000)

        patterns = spade(spiketrains, bin_size=bin_size*pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs*2, dither=dithering*pq.ms, alpha=None, output_format='patterns')['patterns']  #, psr_param=[0, 2, 0]

    except:
        try:
            start = time.time()  # 시작 시간 저장
            signal.signal(signal.SIGALRM, alarm_handler)
            signal.alarm(100000)

            patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs * 2, dither=dithering * pq.ms, alpha=0.2, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

        except:
            try:
                start = time.time()  # 시작 시간 저장
                signal.signal(signal.SIGALRM, alarm_handler)
                signal.alarm(100000)

                patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs * 2, dither=dithering * pq.ms, alpha=0.1, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

            except:
                try:
                    start = time.time()  # 시작 시간 저장
                    signal.signal(signal.SIGALRM, alarm_handler)
                    signal.alarm(100000)

                    patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.05, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

                except:
                    try:
                        start = time.time()  # 시작 시간 저장
                        signal.signal(signal.SIGALRM, alarm_handler)
                        signal.alarm(100000)

                        patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.01, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

                    except TimeOutException as e:
                        time_elapsed = time.time() - start
                        f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
                        f.write(f"{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k_tuples},{time_elapsed * 1000:.0f},{seed}\n")
                        f.close()
                        stopped = True

                    except Exception as e:
                        print(e)
                        time_elapsed = time.time() - start
                        f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
                        f.write(f"{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k_tuples},{time_elapsed * 1000:.0f},{seed}\n")
                        f.close()
                        stopped = True

    if not stopped:
        time_elapsed = time.time() - start
        f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
        f.write(f"{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k_tuples},{time_elapsed * 1000:.0f},{seed}\n")
        f.close()

        os.makedirs(f"./txt/spade/{motif_type}", exist_ok=True)
        os.makedirs(f"./figure/spade/{motif_type}", exist_ok=True)

        k = motif_neurons_numbers[0] - 1

        motif_neuron = []  # motif neurons
        motif_neuron_num = []  # number of neurons in each motif

        for gt in gts:
            NID = gt['NIDs']
            if motif_type == 3:
                lags_dict = {lag: i_lag for i_lag, lags_i in enumerate(gt['lags']) for lag in lags_i}
                motif_neuron_ = np.array([key for key, grp in groupby([NID[lags_dict[lag]] for lag in sorted(lags_dict.keys())])])
                motif_neuron.append(motif_neuron_)
                motif_neuron_num.append(motif_neuron_.size)
            else:
                motif_neuron.append(NID)
                motif_neuron_num.append(NID.size)

        motif_neuron = np.array(motif_neuron, dtype=object)
        motif_neuron_num = np.array(motif_neuron_num)

        motif_neuron_k = motif_neuron[motif_neuron_num >= motif_neurons_numbers[0]]  # neurons in motif of size larger than k
        condition_positive_set = set(itemset_to_number(NIDs, k + 1, sorted(motif_neuron_k_combination)) for motif_neuron_k_i in motif_neuron_k for motif_neuron_k_combination in combinations(motif_neuron_k_i, motif_neurons_numbers[0]))
        condition_positive = len(condition_positive_set)

        itemset_number_list = []
        itemset_number_index_dict = dict()
        itemset_number_index_dict_index = 0
        pvalue_list = []
        for pattern in patterns:
            pvalue = pattern['pvalue']
            for itemset in combinations(pattern['neurons'], k + 1):
                itemset_number = itemset_to_number(NIDs, k + 1, sorted(itemset))
                try:
                    itemset_number_index = itemset_number_index_dict[itemset_number]
                    if pvalue < pvalue_list[itemset_number_index]:
                        pvalue_list[itemset_number_index] = pvalue
                except:
                    itemset_number_list.append(itemset_number)
                    itemset_number_index_dict[itemset_number] = itemset_number_index_dict_index
                    itemset_number_index_dict_index += 1
                    pvalue_list.append(pvalue)

        itemset_number_list = np.asarray(itemset_number_list)
        pvalue_list = np.asarray(pvalue_list)

        np.save(f"./txt/spade/{motif_type}/{motif_type}_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_dither_{dithering}_seed_{seed}_itemset.npy", itemset_number_list)
        np.save(f"./txt/spade/{motif_type}/{motif_type}_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_dither_{dithering}_seed_{seed}_pvalue.npy", pvalue_list)

        ind_pvalue = np.argsort(pvalue_list)

        itemset_number_top_K_pvalue = []
        itemset_number_top_K_pvalue_set = set()
        pvalue_number_top_K_pvalue = -100
        len_itemset_number_top_K_pvalue = 0
        top_K_list[0] = motif_neurons_numbers[1]
        for top_K in top_K_list:
            if len_itemset_number_top_K_pvalue < top_K:
                prev_len_itemset_number_top_K_pvalue = len_itemset_number_top_K_pvalue
                for ind_pval in ind_pvalue[prev_len_itemset_number_top_K_pvalue:]:
                    itemset_number = itemset_number_list[ind_pval]
                    itemset = number_to_itemset(itemset_number, NIDs, k + 1)
                    if itemset_number in itemset_number_top_K_pvalue_set or len(itemset) != len(set(itemset)):
                        continue
                    pvalue = pvalue_list[ind_pval]
                    if pvalue == pvalue_number_top_K_pvalue:
                        itemset_number_top_K_pvalue[-1].append(itemset_number)
                        len_itemset_number_top_K_pvalue += 1
                        continue
                    if len_itemset_number_top_K_pvalue >= top_K:
                        break
                    if itemset_number_top_K_pvalue:
                        len_1 = len(itemset_number_top_K_pvalue[-1])
                        for _ in range(len_1 - 1):
                            itemset_number_top_K_pvalue.append([])
                    itemset_number_top_K_pvalue.append([itemset_number])
                    itemset_number_top_K_pvalue_set.add(itemset_number)
                    pvalue_number_top_K_pvalue = pvalue
                    len_itemset_number_top_K_pvalue += 1

            dcg = 0.0
            true_positive = 0.0
            for i, itemset_numbers in enumerate(itemset_number_top_K_pvalue):
                len_itemset_numbers = len(itemset_numbers)
                if len_itemset_numbers > 0:
                    true_positive_ratio = sum(1.0 for itemset_number in itemset_numbers if itemset_number in condition_positive_set) / len_itemset_numbers
                    dcg_ = 0.0
                    true_positive_ = 0.0
                    for j in range(i, min((i + len_itemset_numbers, top_K))):
                        dcg_ += 1.0 / np.log2(j + 2)
                        true_positive_ += 1.0
                    dcg += true_positive_ratio * dcg_
                    true_positive += true_positive_ratio * true_positive_

            idcg = sum((1.0 / np.log2(i + 2) for i in range(min(condition_positive, top_K))))
            ndcg = min(dcg / idcg, 1.0)

            rc = min(true_positive / min(condition_positive, top_K), 1.0)

            f_ndcg = open(f"./txt/spade/{motif_type}_spade_ndcg_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
            f_ndcg.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k + 1},{top_K},{ndcg},{seed}\n')
            f_ndcg.close()

            f_rc = open(f"./txt/spade/{motif_type}_spade_rc_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
            f_rc.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k + 1},{top_K},{rc},{seed}\n')
            f_rc.close()


def spade_read_ndcg_rc(motif_type, NIDs, recording_time, background_firing_rate, motif_firing_rate, probabilistic_participation, temporal_jitter, time_warping, motif_neurons_numbers, motif_max_lags, motif_max_spikes, bin_size, dithering, start_time, seed, top_K_list, i_exp):
    # Synthetic data generated by SimulMotif
    # Load simulation parameters
    with open("params.yaml") as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params["NIDs"] = NIDs
    params["recording"]["recording_time"] = recording_time
    params["background"]["firing_rate"] = [background_firing_rate, background_firing_rate]

    if probabilistic_participation > 1:
        params["noise"]["probabilistic_participation"] = 1 - 1 / probabilistic_participation

    k_tuples = motif_neurons_numbers[0]

    params["noise"]["temporal_jitter"] = temporal_jitter
    params["noise"]["time_warping"] = time_warping

    params[f"motif_type_{motif_type}"]["firing_rate"] = motif_firing_rate
    params[f"motif_type_{motif_type}"]["neurons"] = motif_neurons_numbers[0]
    params[f"motif_type_{motif_type}"]["motifs"] = motif_neurons_numbers[1]
    if motif_type > 1:
        params[f"motif_type_{motif_type}"]["max_lags"] = motif_max_lags
        winlen = math.ceil((motif_neurons_numbers[0] - 1) * motif_max_lags / bin_size)
        if motif_type == 3:
            params[f"motif_type_{motif_type}"]["max_spikes"] = motif_max_spikes
    else:
        winlen = round(math.ceil(100.0 / bin_size))

    # Genereate non-motif activity
    # spike_time: list containing every spikes
    # spike_time_motif: list containing spikes induced by motifs
    spike_time, spike_time_motif = non_motif_gen(params, seed=6*seed)

    # Generate motif activity
    gts = motif_gen(spike_time, spike_time_motif, motif_type, params, seed=6*seed+motif_type)

    k = motif_neurons_numbers[0] - 1

    motif_neuron = []  # motif neurons
    motif_neuron_num = []  # number of neurons in each motif

    for gt in gts:
        NID = gt['NIDs']
        if motif_type == 3:
            lags_dict = {lag: i_lag for i_lag, lags_i in enumerate(gt['lags']) for lag in lags_i}
            motif_neuron_ = np.array([key for key, grp in groupby([NID[lags_dict[lag]] for lag in sorted(lags_dict.keys())])])
            motif_neuron.append(motif_neuron_)
            motif_neuron_num.append(motif_neuron_.size)
        else:
            motif_neuron.append(NID)
            motif_neuron_num.append(NID.size)

    motif_neuron = np.array(motif_neuron, dtype=object)
    motif_neuron_num = np.array(motif_neuron_num)

    motif_neuron_k = motif_neuron[motif_neuron_num >= motif_neurons_numbers[0]]  # neurons in motif of size larger than k
    condition_positive_set = set(itemset_to_number(NIDs, k + 1, sorted(motif_neuron_k_combination)) for motif_neuron_k_i in motif_neuron_k for motif_neuron_k_combination in combinations(motif_neuron_k_i, motif_neurons_numbers[0]))
    condition_positive = len(condition_positive_set)

    itemset_number_list = np.load(f"./txt/spade/{motif_type}/{motif_type}_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_dither_{dithering}_seed_{seed}_itemset.npy")
    pvalue_list = np.load(f"./txt/spade/{motif_type}/{motif_type}_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_dither_{dithering}_seed_{seed}_pvalue.npy")

    ind_pvalue = np.argsort(pvalue_list)

    itemset_number_top_K_pvalue = []
    itemset_number_top_K_pvalue_set = set()
    pvalue_number_top_K_pvalue = -100
    len_itemset_number_top_K_pvalue = 0
    top_K_list[0] = motif_neurons_numbers[1]
    for top_K in top_K_list:
        if len_itemset_number_top_K_pvalue < top_K:
            prev_len_itemset_number_top_K_pvalue = len_itemset_number_top_K_pvalue
            for ind_pval in ind_pvalue[prev_len_itemset_number_top_K_pvalue:]:
                itemset_number = itemset_number_list[ind_pval]
                itemset = number_to_itemset(itemset_number, NIDs, k + 1)
                if itemset_number in itemset_number_top_K_pvalue_set or len(itemset) != len(set(itemset)):
                    continue
                pvalue = pvalue_list[ind_pval]
                if pvalue == pvalue_number_top_K_pvalue:
                    itemset_number_top_K_pvalue[-1].append(itemset_number)
                    len_itemset_number_top_K_pvalue += 1
                    continue
                if len_itemset_number_top_K_pvalue >= top_K:
                    break
                if itemset_number_top_K_pvalue:
                    len_1 = len(itemset_number_top_K_pvalue[-1])
                    for _ in range(len_1 - 1):
                        itemset_number_top_K_pvalue.append([])
                itemset_number_top_K_pvalue.append([itemset_number])
                itemset_number_top_K_pvalue_set.add(itemset_number)
                pvalue_number_top_K_pvalue = pvalue
                len_itemset_number_top_K_pvalue += 1

        dcg = 0.0
        true_positive = 0.0
        for i, itemset_numbers in enumerate(itemset_number_top_K_pvalue):
            len_itemset_numbers = len(itemset_numbers)
            if len_itemset_numbers > 0:
                true_positive_ratio = sum(1.0 for itemset_number in itemset_numbers if itemset_number in condition_positive_set) / len_itemset_numbers
                dcg_ = 0.0
                true_positive_ = 0.0
                for j in range(i, min((i + len_itemset_numbers, top_K))):
                    dcg_ += 1.0 / np.log2(j + 2)
                    true_positive_ += 1.0
                dcg += true_positive_ratio * dcg_
                true_positive += true_positive_ratio * true_positive_

        idcg = sum((1.0 / np.log2(i + 2) for i in range(min(condition_positive, top_K))))
        ndcg = min(dcg / idcg, 1.0)

        rc = min(true_positive / min(condition_positive, top_K), 1.0)

        f_ndcg = open(f"./txt/spade/{motif_type}_spade_ndcg_{i_exp}.csv", 'a')
        f_ndcg.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k + 1},{top_K},{ndcg},{seed}\n')
        f_ndcg.close()

        f_rc = open(f"./txt/spade/{motif_type}_spade_rc_{i_exp}.csv", 'a')
        f_rc.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{dithering},{k + 1},{top_K},{rc},{seed}\n')
        f_rc.close()


def spade_case(dithering, start_time):
    time_min = datetime.datetime(2014, 4, 27, 0, 0, 0, 0)
    time_max = datetime.datetime(2014, 4, 28, 0, 0, 0, 0)
    time_span = int((time_max - time_min).total_seconds())

    item_list = [214821410, 214826610, 214826563, 214695399, 214829752, 214835002, 214834877, 214684108, 214829660, 214826589, 214828974, 214711280, 214829865, 214829387, 214833755, 214829396, 214829392, 214829366, 214826711, 214829852, 214834880, 214828976, 214834875, 214829810, 214835750, 214829385, 214709792, 214826994, 214829666, 214587028, 214684093, 214584969, 214554277, 214531151, 214829657, 214832717, 214821407, 214829664, 214712132, 214829820, 214832720, 214829747, 214828970, 214829861, 214826705, 214826709, 214820394, 214821332, 214840421, 214821294, 214743493, 214829850, 214835021, 214834873, 214832722, 214587266, 214835752, 214829390, 214743495, 214826666, 214831931, 214836330, 214828959, 214820392, 214826561, 214718210, 214821412, 214706432, 214821320, 214706460, 214828963, 214821350, 214826996, 214826670, 214826936, 214712229, 214821309, 214829034, 214834871, 214829715, 214826874, 214821317, 214712124, 214826992, 214829846, 214712126, 214829822, 214826664, 214744779, 214826805, 214829857, 214829368, 214834997, 214753515, 214840762, 214828965, 214705740, 214821399, 214829379, 214710152]
    item_index = len(item_list)
    NIDs = item_index
    max_pattern = 3
    item_dict = {item: i_item for i_item, item in enumerate(sorted(item_list))}
    item_times = [set() for _ in range(len(item_list))]

    with open('./txt/datasets/ecommerce/yoochoose-clicks_crop.dat', 'r') as input_file:
        reader = csv.reader(input_file, delimiter=',')
        for row in reader:
            time_read = datetime.datetime.strptime(row[1], "%Y-%m-%dT%H:%M:%S.%fZ")
            if time_read < time_min or time_read >= time_max:
                continue
            item = int(row[2])
            if item in item_list:
                item_times[item_dict[item]].add((time_read - time_min).total_seconds())

    for item, item_time in enumerate(item_times):
        item_times[item] = sorted(item_time)

    spiketrains = [neo.core.SpikeTrain(np.clip(np.array(x) * 1000, 0, time_span * 1000) * pq.ms, units='ms', t_stop=time_span * 1000 * pq.ms) for x in item_times]

    for bin_size in [10, 15, 20, 30, 60]:  #60, 30, 20, 15, 10
        winlen = 600 // bin_size
        stopped = False

        try:
            start = time.time()  # 시작 시간 저장
            signal.signal(signal.SIGALRM, alarm_handler)
            signal.alarm(86400)

            patterns = spade(spiketrains, bin_size=bin_size*pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering*pq.ms, alpha=None, output_format='patterns')['patterns']  #, psr_param=[0, 2, 0]

        except:
            try:
                start = time.time()  # 시작 시간 저장
                signal.signal(signal.SIGALRM, alarm_handler)
                signal.alarm(86400)

                patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.2, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

            except:
                try:
                    start = time.time()  # 시작 시간 저장
                    signal.signal(signal.SIGALRM, alarm_handler)
                    signal.alarm(86400)

                    patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.1, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

                except:
                    try:
                        start = time.time()  # 시작 시간 저장
                        signal.signal(signal.SIGALRM, alarm_handler)
                        signal.alarm(86400)

                        patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.05, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

                    except:
                        try:
                            start = time.time()  # 시작 시간 저장
                            signal.signal(signal.SIGALRM, alarm_handler)
                            signal.alarm(86400)

                            patterns = spade(spiketrains, bin_size=bin_size * pq.ms, winlen=winlen, min_neu=2, n_surr=NIDs, dither=dithering * pq.ms, alpha=0.01, output_format='patterns')['patterns']  # , psr_param=[0, 2, 0]

                        except TimeOutException as e:
                            time_elapsed = time.time() - start
                            f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
                            f.write(f"{time_span},{NIDs},{max_pattern},{bin_size},{winlen},{dithering},{time_elapsed * 1000:.0f}\n")
                            f.close()
                            stopped = True

                        except Exception as e:
                            print(e)
                            time_elapsed = time.time() - start
                            f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
                            f.write(f"{time_span},{NIDs},{max_pattern},{bin_size},{winlen},{dithering},{time_elapsed * 1000:.0f}\n")
                            f.close()
                            stopped = True

        if not stopped:
            time_elapsed = time.time() - start
            f = open(f"./txt/spade/yoochoose-clicks_crop_time_{time.strftime('%m.%d_%H.%M.%S', start_time)}.csv", 'a')
            f.write(f"{time_span},{NIDs},{max_pattern},{bin_size},{winlen},{dithering},{time_elapsed * 1000:.0f}\n")
            f.close()

            session_dict = dict()
            items_in_session = list()
            times_in_session = list()
            time_dict = dict()
            time_count_dict = dict()
            item_ids = list()

            with open('./txt/datasets/ecommerce/yoochoose-clicks_crop.dat', 'r') as input_file:
                reader = csv.reader(input_file, delimiter=',')
                session_count = 0
                time_count = 0
                for row in reader:
                    time_read = datetime.datetime.strptime(row[1], "%Y-%m-%dT%H:%M:%S.%fZ").replace(microsecond=0)
                    if time_read < time_min or time_read >= time_max:
                        continue
                    time_read = int((time_read - time_min).total_seconds() // bin_size)
                    item = int(row[2])
                    if item in item_list:
                        session = int(row[0])
                        if session in session_dict:
                            item_indices = [index for index in range(len(items_in_session[session_dict[session]])) if items_in_session[session_dict[session]][index] == item]
                            time_indices = [index for index in range(len(times_in_session[session_dict[session]])) if times_in_session[session_dict[session]][index] == time_read]
                            if not (item in items_in_session[session_dict[session]] and time_read in times_in_session[session_dict[session]] and any(index in item_indices for index in time_indices)):
                                items_in_session[session_dict[session]].append(item)
                                times_in_session[session_dict[session]].append(time_read)
                        else:
                            session_dict[session] = session_count
                            session_count += 1
                            items_in_session.append([item])
                            times_in_session.append([time_read])
                        try:
                            item_ids[time_dict[time_read]].add(item)
                        except:
                            time_dict[time_read] = time_count
                            time_count_dict[time_count] = time_read
                            time_count += 1
                            item_ids.append({item})

            pattern_count_dict = dict()
            pattern_time_dict = dict()
            for session_count, items_in_a_session in enumerate(items_in_session):
                if len(items_in_a_session) >= max_pattern:
                    items_in_session[session_count] = [item_dict[item] for item in items_in_a_session]
                    for comb in combinations(range(len(items_in_session[session_count])), max_pattern):
                        items_in_a_pattern_comb = [items_in_session[session_count][i_comb] for i_comb in comb]
                        if len(set(items_in_a_pattern_comb)) == len(items_in_a_pattern_comb):
                            times_diff_in_a_pattern = list(times_in_session[session_count][i_comb] - times_in_session[session_count][comb[0]] for i_comb in comb[1:])
                            if times_diff_in_a_pattern[-1] < 600:
                                times_diff_number = neurons_to_number(times_diff_in_a_pattern, 600, max_pattern - 2)
                                neurons_number = neurons_to_number(items_in_a_pattern_comb, item_index, max_pattern - 1)
                                if neurons_number in pattern_time_dict:
                                    try:
                                        pattern_count_dict[neurons_number][times_diff_number] += 1
                                    except:
                                        pattern_count_dict[neurons_number][times_diff_number] = 1
                                    pattern_time_dict[neurons_number].add(times_in_session[session_count][comb[0]])
                                else:
                                    pattern_count_dict[neurons_number] = {times_diff_number: 1}
                                    pattern_time_dict[neurons_number] = {times_in_session[session_count][comb[0]]}

            item_count_dict = dict()
            for item_id in item_ids:
                if item_id:
                    for item in [item_dict[item] for item in item_id]:
                        try:
                            item_count_dict[item] += 1
                        except:
                            item_count_dict[item] = 1

            items_in_times = [[] for _ in range(max(time_count_dict.values()) + 1)]
            for time_count, item_id in enumerate(item_ids):
                if len(item_id) >= max_pattern:
                    items_in_times[time_count_dict[time_count]] = sorted([item_dict[item] for item in item_id])

            times_items = [set() for _ in range(len(item_list))]
            for time_read, item_id in enumerate(items_in_times):
                if item_id:
                    for item in item_id:
                        times_items[item].add(time_read)

            times_items = [sorted(times_item) for times_item in times_items]

            time_span = int(((time_max - time_min).total_seconds() + bin_size - 0.000001) // bin_size)
            k = max_pattern - 1

            os.makedirs(f"./txt/spade/yoochoose-clicks_crop", exist_ok=True)
            os.makedirs(f"./figure/spade/yoochoose-clicks_crop", exist_ok=True)

            neurons_support_sum_dict = dict()
            neurons_support_max_dict = dict()

            for pattern in patterns:
                support = pattern['signature'][1]
                for itemset in combinations(pattern['neurons'], k + 1):
                    if len(itemset) == len(set(itemset)):
                        itemset_number = itemset_to_number(NIDs, k + 1, itemset)
                        try:
                            neurons_support_sum_dict[itemset_number] += support
                            if support > neurons_support_max_dict[itemset_number]:
                                neurons_support_max_dict[itemset_number] = support
                        except:
                            neurons_support_sum_dict[itemset_number] = support
                            neurons_support_max_dict[itemset_number] = support

            print()
            print(time_span, bin_size, winlen)
            neurons_support_sum_count = sorted(neurons_support_sum_dict.items(), key=lambda x: x[1], reverse=True)
            neurons_support_max_count = sorted(neurons_support_max_dict.items(), key=lambda x: x[1], reverse=True)

            neurons_dict = dict()
            print("neurons_support_sum_count")
            for neurons_number, count in neurons_support_sum_count[:100]:
                if neurons_number not in neurons_dict:
                    neurons_first_time = set()
                    neurons = neurons_number_to_unsorted_neurons(neurons_number, item_index, max_pattern - 1)
                    neurons = neurons
                    for first_time in times_items[neurons[0]]:
                        for second_time in [time_read for time_read in times_items[neurons[1]] if first_time <= time_read <= first_time + winlen - 1]:
                            if any(second_time <= time_read <= first_time + winlen for time_read in times_items[neurons[2]]):
                                neurons_first_time.add(first_time)
                                break
                    try:
                        pattern_time_len = len(pattern_time_dict[neurons_number])
                    except:
                        pattern_time_len = 0
                    neurons_dict[neurons_number] = f"{neurons}/{len(neurons_first_time)}/{pattern_time_len}/{len(neurons_first_time) - pattern_time_len}"
                print(neurons_dict[neurons_number])

            print("neurons_support_max_count")
            for neurons_number, count in neurons_support_max_count[:100]:
                if neurons_number not in neurons_dict:
                    neurons_first_time = set()
                    neurons = neurons_number_to_unsorted_neurons(neurons_number, item_index, max_pattern - 1)
                    neurons = neurons
                    for first_time in times_items[neurons[0]]:
                        for second_time in [time_read for time_read in times_items[neurons[1]] if first_time <= time_read <= first_time + winlen - 1]:
                            if any(second_time <= time_read <= first_time + winlen for time_read in times_items[neurons[2]]):
                                neurons_first_time.add(first_time)
                                break
                    try:
                        pattern_time_len = len(pattern_time_dict[neurons_number])
                    except:
                        pattern_time_len = 0
                    neurons_dict[neurons_number] = f"{neurons}/{len(neurons_first_time)}/{pattern_time_len}/{len(neurons_first_time) - pattern_time_len}"
                print(neurons_dict[neurons_number])
