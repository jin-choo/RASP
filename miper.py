import numpy as np, yaml, os, csv, datetime
from CN2Simulator.motif_gen import *
from itertools import combinations, groupby


def neurons_to_number(neurons, max_neuron, k_tuple):
    number = neurons[0] * pow(max_neuron, k_tuple)
    for k_neurons in range(1, k_tuple + 1):
        number += neurons[k_neurons] * pow(max_neuron, k_tuple - k_neurons)
    return number


def neurons_number_to_neurons(number, max_neuron, k_tuple):
    q, mod = divmod(number, pow(max_neuron, k_tuple))
    neurons = [q]
    for k_neurons in range(1, k_tuple + 1):
        q, mod = divmod(mod, pow(max_neuron, k_tuple - k_neurons))
        neurons.append(q)
    return tuple(sorted(neurons))


def neurons_number_to_unsorted_neurons(number, max_neuron, k_tuple):
    q, mod = divmod(number, pow(max_neuron, k_tuple))
    neurons = [q]
    for k_neurons in range(1, k_tuple + 1):
        q, mod = divmod(mod, pow(max_neuron, k_tuple - k_neurons))
        neurons.append(q)
    return neurons


def miper_read_ndcg_rc(motif_type, NIDs, recording_time, background_firing_rate, motif_firing_rate, probabilistic_participation, temporal_jitter, time_warping, motif_neurons_numbers, motif_max_lags, motif_max_spikes, bin_size, seed, top_K_list, i_exp):
    # Synthetic data generated by SimulMotif
    # Load simulation parameters
    with open("params.yaml") as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params["NIDs"] = NIDs
    params["recording"]["recording_time"] = recording_time
    params["background"]["firing_rate"] = [background_firing_rate, background_firing_rate]

    if probabilistic_participation > 1:
        params["noise"]["probabilistic_participation"] = 1 - 1 / probabilistic_participation

    params["noise"]["temporal_jitter"] = temporal_jitter
    params["noise"]["time_warping"] = time_warping

    params[f"motif_type_{motif_type}"]["firing_rate"] = motif_firing_rate
    params[f"motif_type_{motif_type}"]["neurons"] = motif_neurons_numbers[0]
    params[f"motif_type_{motif_type}"]["motifs"] = motif_neurons_numbers[1]
    if motif_type > 1:
        params[f"motif_type_{motif_type}"]["max_lags"] = motif_max_lags
        winlen = math.ceil((motif_neurons_numbers[0] - 1) * motif_max_lags / bin_size)
        # winlen = math.ceil(((motif_neurons_numbers[0] - 1) * motif_max_lags + 2 * temporal_jitter) / bin_size)
        if motif_type == 3:
            params[f"motif_type_{motif_type}"]["max_spikes"] = motif_max_spikes
        interlen = math.ceil(motif_max_lags / bin_size)
    else:
        winlen = round(math.ceil(100.0 / bin_size))
        # winlen = math.ceil(2 * temporal_jitter / bin_size + 2)
        interlen = winlen

    if os.path.exists(f"./MIPER/txt/{motif_type}_miper_pru_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation:.1f}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_seed_{seed}.txt"):
        # Genereate non-motif activity
        # spike_time: list containing every spikes
        # spike_time_motif: list containing spikes induced by motifs
        spike_time, spike_time_motif = non_motif_gen(params, seed=6*seed)

        # Generate motif activity
        gts = motif_gen(spike_time, spike_time_motif, motif_type, params, seed=6*seed+motif_type)

        motif_neuron = []  # motif neurons
        motif_neuron_num = []  # number of neurons in each motif

        for gt in gts:
            NID = gt['NIDs']
            if motif_type == 3:
                lags_dict = {lag: i_lag for i_lag, lags_i in enumerate(gt['lags']) for lag in lags_i}
                motif_neuron_ = np.asarray([key for key, grp in groupby([NID[lags_dict[lag]] for lag in sorted(lags_dict.keys())])])
                motif_neuron.append(motif_neuron_)
                motif_neuron_num.append(motif_neuron_.size)
            else:
                motif_neuron.append(NID)
                motif_neuron_num.append(NID.size)

        motif_neuron = np.asarray(motif_neuron, dtype=object)
        motif_neuron_num = np.asarray(motif_neuron_num)

        motif_neuron_k = motif_neuron[motif_neuron_num >= motif_neurons_numbers[0]]  # neurons in motif of size larger than k
        condition_positive_set = set(neurons_to_number(sorted(motif_neuron_k_combination), NIDs, motif_neurons_numbers[0] - 1) for motif_neuron_k_i in motif_neuron_k for motif_neuron_k_combination in combinations(motif_neuron_k_i, motif_neurons_numbers[0]))
        condition_positive = len(condition_positive_set)

        neurons_number_list = []
        exp_list = []

        for line in open(f"./MIPER/txt/{motif_type}_miper_pru_NIDs_{NIDs}_time_{recording_time}_bg_{background_firing_rate:.2f}_pp_{probabilistic_participation:.1f}_tj_{temporal_jitter}_tw_{time_warping}_mt_{motif_firing_rate:.2f}_{motif_neurons_numbers[0]}_{motif_neurons_numbers[1]}_{motif_max_lags}_{motif_max_spikes}_bin_{bin_size}_winlen_{winlen}_seed_{seed}.txt", 'r'):
            line_split = line.rstrip('\n').split()
            neurons_number_list.append(neurons_to_number(sorted(map(int, line_split[0].split('@'))), NIDs, motif_neurons_numbers[0] - 1))
            exp_list.append(float(line_split[2]))

        neurons_number_list = np.asarray(neurons_number_list)
        exp_list = np.asarray(exp_list)
        ind_exp = np.argsort(exp_list)[::-1]

        neurons_number_top_K_exp = []
        neurons_number_top_K_exp_set = set()
        exp_number_top_K_exp = -100
        len_neurons_number_top_K_exp = 0
        top_K_list[0] = motif_neurons_numbers[1]
        for top_K in top_K_list:
            if len_neurons_number_top_K_exp < top_K:
                prev_len_neurons_number_top_K_exp = len_neurons_number_top_K_exp
                for ind_pval in ind_exp[prev_len_neurons_number_top_K_exp:]:
                    neurons_number = neurons_number_list[ind_pval]
                    if neurons_number in neurons_number_top_K_exp_set:
                        continue
                    exp = exp_list[ind_pval]
                    if exp == exp_number_top_K_exp:
                        neurons_number_top_K_exp[-1].append(neurons_number)
                        len_neurons_number_top_K_exp += 1
                        continue
                    if len_neurons_number_top_K_exp >= top_K:
                        break
                    if neurons_number_top_K_exp:
                        len_1 = len(neurons_number_top_K_exp[-1])
                        for _ in range(len_1 - 1):
                            neurons_number_top_K_exp.append([])
                    neurons_number_top_K_exp.append([neurons_number])
                    neurons_number_top_K_exp_set.add(neurons_number)
                    exp_number_top_K_exp = exp
                    len_neurons_number_top_K_exp += 1

            dcg = 0.0
            true_positive = 0.0
            for i, neuron_numbers in enumerate(neurons_number_top_K_exp):
                len_neuron_numbers = len(neuron_numbers)
                if len_neuron_numbers > 0:
                    true_positive_ratio = sum(1.0 for neuron_number in neuron_numbers if neuron_number in condition_positive_set) / len_neuron_numbers
                    dcg_ = 0.0
                    true_positive_ = 0.0
                    for j in range(i, min(i + len_neuron_numbers, top_K)):
                        dcg_ += 1.0 / np.log2(j + 2)
                        true_positive_ += 1.0
                    dcg += true_positive_ratio * dcg_
                    true_positive += true_positive_ratio * true_positive_

            idcg = sum((1.0 / np.log2(i + 2) for i in range(min(condition_positive, top_K))))
            ndcg = min(dcg / idcg, 1.0)

            rc = min(true_positive / min(condition_positive, top_K), 1.0)

            f_ndcg = open(f"./txt/miper/miper_{motif_type}_ndcg_{i_exp}.csv", 'a')
            f_ndcg.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation:.1f},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{interlen},{motif_neurons_numbers[0]},{top_K},{ndcg},{seed}\n')
            f_ndcg.close()

            f_rc = open(f"./txt/miper/miper_{motif_type}_rc_{i_exp}.csv", 'a')
            f_rc.write(f'{motif_type},{NIDs},{recording_time},{background_firing_rate:.2f},{probabilistic_participation:.1f},{temporal_jitter},{time_warping},{motif_firing_rate:.2f},{motif_neurons_numbers[0]},{motif_neurons_numbers[1]},{motif_max_lags},{motif_max_spikes},{bin_size},{winlen},{interlen},{motif_neurons_numbers[0]},{top_K},{rc},{seed}\n')
            f_rc.close()


def miper_read_case():
    time_min = datetime.datetime(2014, 4, 27, 0, 0, 0, 0)
    time_max = datetime.datetime(2014, 4, 28, 0, 0, 0, 0)

    # 100
    item_list = [214821410, 214826610, 214826563, 214695399, 214829752, 214835002, 214834877, 214684108, 214829660, 214826589, 214828974, 214711280, 214829865, 214829387, 214833755, 214829396, 214829392, 214829366, 214826711, 214829852, 214834880, 214828976, 214834875, 214829810, 214835750, 214829385, 214709792, 214826994, 214829666, 214587028, 214684093, 214584969, 214554277, 214531151, 214829657, 214832717, 214821407, 214829664, 214712132, 214829820, 214832720, 214829747, 214828970, 214829861, 214826705, 214826709, 214820394, 214821332, 214840421, 214821294, 214743493, 214829850, 214835021, 214834873, 214832722, 214587266, 214835752, 214829390, 214743495, 214826666, 214831931, 214836330, 214828959, 214820392, 214826561, 214718210, 214821412, 214706432, 214821320, 214706460, 214828963, 214821350, 214826996, 214826670, 214826936, 214712229, 214821309, 214829034, 214834871, 214829715, 214826874, 214821317, 214712124, 214826992, 214829846, 214712126, 214829822, 214826664, 214744779, 214826805, 214829857, 214829368, 214834997, 214753515, 214840762, 214828965, 214705740, 214821399, 214829379, 214710152]

    for binSize in [30, 60]:
        session_dict = dict()
        items_in_session = list()
        times_in_session = list()
        time_dict = dict()
        time_count_dict = dict()
        item_ids = list()

        with open('./txt/datasets/ecommerce/yoochoose-clicks_crop.dat', 'r') as input_file:
            reader = csv.reader(input_file, delimiter=',')
            session_count = 0
            time_count = 0
            for row in reader:
                time = datetime.datetime.strptime(row[1], "%Y-%m-%dT%H:%M:%S.%fZ").replace(microsecond=0)
                if time < time_min or time >= time_max:
                    continue
                time = int((time - time_min).total_seconds() // binSize)
                item = int(row[2])
                if item in item_list:
                    session = int(row[0])
                    if session in session_dict:
                        item_indices = [index for index in range(len(items_in_session[session_dict[session]])) if items_in_session[session_dict[session]][index] == item]
                        time_indices = [index for index in range(len(times_in_session[session_dict[session]])) if times_in_session[session_dict[session]][index] == time]
                        if not (item in items_in_session[session_dict[session]] and time in times_in_session[session_dict[session]] and any(index in item_indices for index in time_indices)):
                            items_in_session[session_dict[session]].append(item)
                            times_in_session[session_dict[session]].append(time)
                    else:
                        session_dict[session] = session_count
                        session_count += 1
                        items_in_session.append([item])
                        times_in_session.append([time])
                    try:
                        item_ids[time_dict[time]].add(item)
                    except:
                        time_dict[time] = time_count
                        time_count_dict[time_count] = time
                        time_count += 1
                        item_ids.append({item})

        item_dict = {item: i_item for i_item, item in enumerate(sorted(item_list))}
        item_index = len(item_list)

        max_pattern = 3
        pattern_count_dict = dict()
        pattern_time_dict = dict()
        for session_count, items_in_a_session in enumerate(items_in_session):
            if len(items_in_a_session) >= max_pattern:
                items_in_session[session_count] = [item_dict[item] for item in items_in_a_session]
                for comb in combinations(range(len(items_in_session[session_count])), max_pattern):
                    items_in_a_pattern_comb = [items_in_session[session_count][i_comb] for i_comb in comb]
                    if len(set(items_in_a_pattern_comb)) == len(items_in_a_pattern_comb):
                        times_diff_in_a_pattern = list(times_in_session[session_count][i_comb] - times_in_session[session_count][comb[0]] for i_comb in comb[1:])
                        if times_diff_in_a_pattern[-1] < 600:
                            times_diff_number = neurons_to_number(times_diff_in_a_pattern, 600, max_pattern - 2)
                            neurons_number = neurons_to_number(items_in_a_pattern_comb, item_index, max_pattern - 1)
                            if neurons_number in pattern_time_dict:
                                try:
                                    pattern_count_dict[neurons_number][times_diff_number] += 1
                                except:
                                    pattern_count_dict[neurons_number][times_diff_number] = 1
                                pattern_time_dict[neurons_number].add(times_in_session[session_count][comb[0]])
                            else:
                                pattern_count_dict[neurons_number] = {times_diff_number: 1}
                                pattern_time_dict[neurons_number] = {times_in_session[session_count][comb[0]]}

        item_count_dict = dict()
        for item_id in item_ids:
            if item_id:
                for item in [item_dict[item] for item in item_id]:
                    try:
                        item_count_dict[item] += 1
                    except:
                        item_count_dict[item] = 1

        items_in_times = [[] for _ in range(max(time_count_dict.values()) + 1)]
        for time_count, item_id in enumerate(item_ids):
            if len(item_id) >= max_pattern:
                items_in_times[time_count_dict[time_count]] = sorted([item_dict[item] for item in item_id])

        times_items = [set() for _ in range(len(item_list))]
        for time, item_id in enumerate(items_in_times):
            if item_id:
                for item in item_id:
                    times_items[item].add(time)

        times_items = [sorted(times_item) for times_item in times_items]

        time_span = int(((time_max - time_min).total_seconds() + binSize - 0.000001) // binSize)
        winlen = 600 // binSize

        max_time_in_session = winlen - 1
        neurons_support_sum_dict = dict()
        neurons_support_max_dict = dict()
        if os.path.exists(f'./MIPER/txt/datasets/ecommerce/yoochoose-clicks_crop_time_{time_span}_item_{item_index}_bin_{binSize}_winlen_{winlen}_interlen_{max_time_in_session}.txt'):
            for line in open(f'./MIPER/txt/datasets/ecommerce/yoochoose-clicks_crop_time_{time_span}_item_{item_index}_bin_{binSize}_winlen_{winlen}_interlen_{max_time_in_session}.txt', 'r'):
                line_split = line.rstrip('\n').split()
                neurons_number = neurons_to_number(list(map(int, line_split[0].split('@'))), item_index, max_pattern - 1)
                support = int(line_split[1])
                try:
                    neurons_support_sum_dict[neurons_number] += support
                    if support > neurons_support_max_dict[neurons_number]:
                        neurons_support_max_dict[neurons_number] = support
                except:
                    neurons_support_sum_dict[neurons_number] = support
                    neurons_support_max_dict[neurons_number] = support

            print()
            print(time_span, binSize, winlen)
            neurons_support_sum_count = sorted(neurons_support_sum_dict.items(), key=lambda x: x[1], reverse=True)
            neurons_support_max_count = sorted(neurons_support_max_dict.items(), key=lambda x: x[1], reverse=True)

        neurons_dict = dict()

        print("neurons_support_sum_count")
        for neurons_number, count in neurons_support_sum_count[:100]:
            if neurons_number not in neurons_dict:
                neurons_first_time = set()
                neurons = neurons_number_to_unsorted_neurons(neurons_number, item_index, max_pattern - 1)
                neurons = neurons
                for first_time in times_items[neurons[0]]:
                    for second_time in [time for time in times_items[neurons[1]] if first_time <= time <= first_time + winlen - 1]:
                        if any(second_time <= time <= first_time + winlen for time in times_items[neurons[2]]):
                            neurons_first_time.add(first_time)
                            break
                try:
                    pattern_time_len = len(pattern_time_dict[neurons_number])
                except:
                    pattern_time_len = 0
                neurons_dict[neurons_number] = f"{neurons}/{len(neurons_first_time)}/{pattern_time_len}/{len(neurons_first_time) - pattern_time_len}"
            print(neurons_dict[neurons_number])

        print("neurons_support_max_count")
        for neurons_number, count in neurons_support_max_count[:100]:
            if neurons_number not in neurons_dict:
                neurons_first_time = set()
                neurons = neurons_number_to_unsorted_neurons(neurons_number, item_index, max_pattern - 1)
                neurons = neurons
                for first_time in times_items[neurons[0]]:
                    for second_time in [time for time in times_items[neurons[1]] if first_time <= time <= first_time + winlen - 1]:
                        if any(second_time <= time <= first_time + winlen for time in times_items[neurons[2]]):
                            neurons_first_time.add(first_time)
                            break
                try:
                    pattern_time_len = len(pattern_time_dict[neurons_number])
                except:
                    pattern_time_len = 0
                neurons_dict[neurons_number] = f"{neurons}/{len(neurons_first_time)}/{pattern_time_len}/{len(neurons_first_time) - pattern_time_len}"
            print(neurons_dict[neurons_number])
